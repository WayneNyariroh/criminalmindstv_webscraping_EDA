Using Python for Web Scraping, Cleaning and Analyzing Data<br>

BeautifulSoup, requests library, pandas, matplotlib, seaborn

The steps to taken:
- Using the read_html() methods where html data is in tables
- Using the requests library to 'get' web page(s) locally
- Inspecting the webpage's HTML source and knowing the relevant tags that contains the information we seek.
- Using Beautiful Soup to parse (break into components) and extracting relevant information from the html document into a dataframe.
- Cleaning our data and data types, and some feature engineering where necessary.
- Exporting our scraped datasets into relevant files.
- Data Analysis